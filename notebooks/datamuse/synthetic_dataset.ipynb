{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better clue datasets\n",
    "\n",
    "I don't have a labelled dataset because none of my friends want to come up with thousands of clues with me :(\n",
    "    \n",
    "To create some clues that are based on having similar meaning or based on words triggered by a codeword, we can use the [Datamuse API](https://www.datamuse.com/api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200000 keys\n"
     ]
    }
   ],
   "source": [
    "import decryptoai.word2vec_loader.loader as wv_loader\n",
    "\n",
    "limit = 200_000\n",
    "print(f\"Loading {limit} keys\")\n",
    "google_news_wv = wv_loader.load_word2vec_keyedvectors(limit=limit, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meaning dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jadenrodriguez/Projects/decrypto-ai-research/data/meaning.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m official_words \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(wv_loader\u001b[39m.\u001b[39mofficial_keyword_to_word, dg\u001b[39m.\u001b[39mofficial_words\u001b[39m.\u001b[39menglish\u001b[39m.\u001b[39mwords))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading meaning dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m meaning_dataset \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m load_dataset_from_path(meaning_dataset_path, \u001b[39m\"\u001b[39m\u001b[39mwords?ml\u001b[39m\u001b[39m\"\u001b[39m, official_words)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading triggerword dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m triggerword_dataset \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m load_dataset_from_path(triggerword_dataset_path, \u001b[39m\"\u001b[39m\u001b[39mwords?rel_trg\u001b[39m\u001b[39m\"\u001b[39m, official_words)\n",
      "\u001b[1;32m/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     responses \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m fetch_text_responses(urls, words)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     dataset \u001b[39m=\u001b[39m create_dataset_dict(responses)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mstr\u001b[39;49m(path), \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         json\u001b[39m.\u001b[39mdump(dataset, f)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jadenrodriguez/Projects/decrypto-ai-research/notebooks/datamuse/synthetic_dataset.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/decrypto-ai-research/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jadenrodriguez/Projects/decrypto-ai-research/data/meaning.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import decryptogame as dg\n",
    "import decryptoai.config as cfg\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "def datamuse_url(endpoint: str, words: list[str]): # can add stuff for prefix/suffix support later\n",
    "    query_str = '+'.join(words)\n",
    "    return f\"https://api.datamuse.com/{endpoint}={query_str}\"\n",
    "\n",
    "async def fetch_text_response(session, url, return_id=None):\n",
    "    # return ID let's us associate the result with a paramater\n",
    "    # this allows us to know which word the reponse text is associated with\n",
    "    # despite being called asynchronously\n",
    "    async with session.get(url) as response:\n",
    "        text = await response.text()\n",
    "        return return_id, text\n",
    "\n",
    "async def fetch_text_responses(urls, return_ids):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        api_calls = [fetch_text_response(session, *args) for args in zip(urls, return_ids)]\n",
    "        return [await response for response in asyncio.as_completed(api_calls)]\n",
    "\n",
    "def create_dataset_dict(responses):\n",
    "    meaning_dataset = {}\n",
    "    for word, response in responses:\n",
    "        response_object = json.loads(response)\n",
    "        if response_object:\n",
    "            meaning_dataset[word] = response_object\n",
    "    return meaning_dataset\n",
    "\n",
    "\n",
    "# process responses for local storage\n",
    "\n",
    "async def load_dataset_from_path(path: pathlib.Path, endpoint: str, words):\n",
    "    if not path.exists():\n",
    "        if not path.parent.exists():\n",
    "            path.parent.mkdir()\n",
    "        urls = [datamuse_url(endpoint, [word]) for word in words]\n",
    "        responses = await fetch_text_responses(urls, words)\n",
    "\n",
    "        dataset = create_dataset_dict(responses)\n",
    "\n",
    "        with open(str(path), 'w') as f:\n",
    "            json.dump(dataset, f)\n",
    "    else:\n",
    "        with open(str(path)) as f:\n",
    "            dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "meaning_dataset_path = cfg.MEANING_JSON_PATH\n",
    "triggerword_dataset_path = cfg.TRIGGERWORD_JSON_PATH\n",
    "\n",
    "official_words = list(map(wv_loader.official_keyword_to_word, dg.official_words.english.words))\n",
    "\n",
    "print(\"Loading meaning dataset\")\n",
    "meaning_dataset = await load_dataset_from_path(meaning_dataset_path, \"words?ml\", official_words)\n",
    "\n",
    "print(\"Loading triggerword dataset\")\n",
    "triggerword_dataset = await load_dataset_from_path(triggerword_dataset_path, \"words?rel_trg\", official_words)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can use the similar meaning and trigger word datasets to come up with reasonable clues that would be more of a challenge for our Guesser. That is, let's see if we can make clues that follow the rules and that I might be able to guess myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WINTER', 'PATH', 'FESTIVAL', 'POISON')\n",
      "(0, 1, 3)\n",
      "('weather', 'street', 'drug')\n",
      "('skiing', 'graph', 'pill')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def filter_illegal_cluewords(legal_clue_func, datamuse_dataset):\n",
    "    filtered_dataset = {}\n",
    "    for keyword, info in datamuse_dataset.items():\n",
    "        legal_info = [word_info for word_info in info if legal_clue_func(keyword, word_info[\"word\"])]\n",
    "        filtered_dataset[keyword] = legal_info\n",
    "    return filtered_dataset        \n",
    "\n",
    "def clueword_from_dataset(datamuse_dataset, code_word, seed=400):\n",
    "    candidate_words = []\n",
    "    scores = []\n",
    "    if code_word not in datamuse_dataset:\n",
    "        return \"garbage\"\n",
    "    for word_info in datamuse_dataset[code_word]:\n",
    "        candidate_words.append(word_info[\"word\"])\n",
    "        scores.append(word_info[\"score\"])\n",
    "    np_scores = np.asarray(scores)\n",
    "    probabilities = np_scores / np.sum(np_scores)\n",
    "    [clue] = random.Random(seed).choices(candidate_words, probabilities)\n",
    "    return clue\n",
    "\n",
    "def clue_from_codewords(datamuse_dataset, codewords, seed=100):\n",
    "    return tuple(clueword_from_dataset(datamuse_dataset, word, seed=seed) for word in codewords)\n",
    "\n",
    "def legal(keyword, word):\n",
    "    no_inclusion = (keyword not in word) and (word not in keyword)\n",
    "    no_british = word not in [\"armour\", \"moustache\", \"theatre\", \"mustache\", \"armor\", \"theater\"]\n",
    "    return no_inclusion and no_british and word in google_news_wv \n",
    "\n",
    "def codewords(keyword_card, code):\n",
    "    return  [wv_loader.official_keyword_to_word(keyword_card[i]) for i in code]\n",
    "\n",
    "\n",
    "meaning_dataset = filter_illegal_cluewords(legal, meaning_dataset)\n",
    "triggerword_dataset = filter_illegal_cluewords(legal, triggerword_dataset)\n",
    "\n",
    "keyword_card_length = 4\n",
    "\n",
    "[test_keyword_card] = next(dg.generators.RandomKeywordCards(card_lengths=[keyword_card_length], seed=200))\n",
    "[test_code] = next(dg.generators.RandomCodes([test_keyword_card], seed=200))\n",
    "test_codewords = codewords(test_keyword_card, test_code)\n",
    "\n",
    "print(test_keyword_card)\n",
    "print(test_code)\n",
    "\n",
    "meaning_clue = clue_from_codewords(meaning_dataset, test_codewords)\n",
    "triggerword_clue = clue_from_codewords(triggerword_dataset, test_codewords)\n",
    "\n",
    "print(meaning_clue)\n",
    "print(triggerword_clue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are some reasonable clues! Let's save a csv for ease-of-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword1</th>\n",
       "      <th>keyword2</th>\n",
       "      <th>keyword3</th>\n",
       "      <th>keyword4</th>\n",
       "      <th>clue1</th>\n",
       "      <th>clue2</th>\n",
       "      <th>clue3</th>\n",
       "      <th>code_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>electricians</td>\n",
       "      <td>leg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>electricians</td>\n",
       "      <td>ancestry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>leg</td>\n",
       "      <td>electricians</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>leg</td>\n",
       "      <td>ancestry</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>ancestry</td>\n",
       "      <td>electricians</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keyword1 keyword2 keyword3 keyword4     clue1         clue2         clue3  \\\n",
       "0  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle  electricians           leg   \n",
       "1  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle  electricians      ancestry   \n",
       "2  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle           leg  electricians   \n",
       "3  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle           leg      ancestry   \n",
       "4  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle      ancestry  electricians   \n",
       "\n",
       "   code_index  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from itertools import permutations\n",
    "\n",
    "def all_possible_codes(keyword_card_length=4, clue_length=3):\n",
    "    return list(permutations(range(keyword_card_length), clue_length))\n",
    "\n",
    "\n",
    "meaning_csv_path = cfg.MEANING_CSV_PATH\n",
    "triggerword_csv_path = cfg.TRIGGERWORD_CSV_PATH\n",
    "\n",
    "if not meaning_csv_path.exists() or not triggerword_csv_path.exists():\n",
    "\n",
    "    num_keyword_cards = 1500\n",
    "    codes = all_possible_codes()\n",
    "    keyword_card_generator = dg.generators.RandomKeywordCards(card_lengths=[keyword_card_length], seed=100)\n",
    "\n",
    "    meaning_data = []\n",
    "    triggerword_data = []\n",
    "    for _, [keyword_card] in zip(range(num_keyword_cards), keyword_card_generator):\n",
    "        for i, code in enumerate(codes):\n",
    "            meaning_clue = clue_from_codewords(meaning_dataset, codewords(keyword_card, code))\n",
    "            meaning_data.append(keyword_card + meaning_clue + (i,))\n",
    "            \n",
    "            triggerword_clue = clue_from_codewords(triggerword_dataset, codewords(keyword_card, code))\n",
    "            triggerword_data.append(keyword_card + triggerword_clue + (i,))\n",
    "\n",
    "    header = [\"keyword1\", \"keyword2\", \"keyword3\", \"keyword4\", \"clue1\",  \"clue2\",  \"clue3\", \"code_index\"]\n",
    "    meaning_df = pandas.DataFrame(meaning_data, columns=header)\n",
    "    triggerword_df = pandas.DataFrame(triggerword_data, columns=header)\n",
    "                                      \n",
    "    meaning_df.to_csv(str(meaning_csv_path), index=False)\n",
    "    triggerword_df.to_csv(str(triggerword_csv_path), index=False)\n",
    "\n",
    "else:\n",
    "    meaning_df = pandas.read_csv(str(meaning_csv_path))\n",
    "\n",
    "meaning_df.sample(frac=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have tens of thousands of clues to reference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
