{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97556bc6",
   "metadata": {},
   "source": [
    "# Using Word2Vec Embedding to extend POC Guesser\n",
    "\n",
    "We can use Gensim to make a more powerful version of our Proof-of-Concept. The main limitation will be guesses that lie outside of the training corpora; we might tackle this later with FastText. For now, let's see if we can make less of a toy version using the Google News Skip-Gram model with 300-feature embeddings (requires ~2GB).\n",
    "\n",
    "Make sure to update SSL Certificate to download if required: \n",
    "```\n",
    "pip install -U certifi\n",
    "\n",
    "/Applications/Python 3.X/Install Certificates.command\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea025752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200000 from saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import gensim.models\n",
    "\n",
    "saved_path_name = \"word2vec-google-news-300_c\"\n",
    "limit = 200_000\n",
    "\n",
    "if not os.path.exists(saved_path_name):\n",
    "    print(\"Checking cache and downloading\")\n",
    "    google_news_wv = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "    google_news_wv.save_word2vec_format(saved_path_name)\n",
    "    print(\"Saved to disk in C format\")\n",
    "    del google_news_wv\n",
    "\n",
    "print(f\"Loading {limit} from saved\")\n",
    "google_news_wv = gensim.models.KeyedVectors.load_word2vec_format(saved_path_name, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf202df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "word #0/200000 is </s>\n",
      "word #1/200000 is in\n",
      "word #2/200000 is for\n",
      "word #3/200000 is that\n",
      "word #4/200000 is is\n",
      "word #5/200000 is on\n",
      "word #6/200000 is ##\n",
      "word #7/200000 is The\n",
      "word #8/200000 is with\n",
      "word #9/200000 is said\n"
     ]
    }
   ],
   "source": [
    "print(len(google_news_wv.index_to_key))\n",
    "for index, word in enumerate(google_news_wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(google_news_wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490cf5f1",
   "metadata": {},
   "source": [
    "Doing stuff with the whole wordset is really slow, slower than I'd like at least. It also requires more memory than I have on my machine. I could see how effective caching stuff is but I think it would make more sense to reduce computation cost and space.\n",
    "\n",
    "We can try prioritizing similarity; I also think it would make sense to focus on words which are determined to have a higher probability by the guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ba9c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hot', 'hottest', 'hotter', 'sizzling', 'scorching']\n",
      "[0.6659734845161438, 0.6050904989242554, 0.5794501900672913, 0.5456804633140564, 0.5294975638389587]\n",
      "[0.05301143256911484, 0.05908263408238489, 0.08296832545223916, 0.07099674806561757, 0.08010270170819725]\n",
      "['cool', 'heated', 'cooled', 'cools', 'toasty']\n",
      "[0.515114963054657, 0.5010007619857788, 0.4956398010253906, 0.4776151478290558, 0.47559136152267456]\n",
      "[0.09783667977494581, 0.06985106247671215, 0.07783893994317491, 0.07441751782190638, 0.18550624028290613]\n",
      "0.46021384\n",
      "0.43215373\n",
      "0.38504532\n",
      "-0.21174502\n",
      "-0.17452702\n",
      "-0.16243233\n",
      "0.20240277\n",
      "0.04439323\n",
      "-0.0021879696\n"
     ]
    }
   ],
   "source": [
    "word = \"hot\"\n",
    "\n",
    "# This takes forever\n",
    "\n",
    "# similarity_sum = 0\n",
    "# for i, other_word in enumerate(google_news_wv.index_to_key):\n",
    "#     similarity_sum += google_news_wv.similarity(other_word, word)\n",
    "#     if i % 1000 == 0:\n",
    "#         print(i)\n",
    "\n",
    "# Instead, let's prioritize by similarity\n",
    "similarity_sum = 0\n",
    "words = []\n",
    "similarities = []\n",
    "for word, similarity in google_news_wv.most_similar(positive=[word], topn=10):\n",
    "    words.append(word)\n",
    "    similarity_sum += abs(similarity)\n",
    "    similarities.append(similarity)\n",
    "log_similarity_sum = math.log(similarity_sum)\n",
    "word_log_probabilities = [math.log(abs(google_news_wv.similarity(word, other_word))) - log_similarity_sum  for other_word in words]\n",
    "print(words[:5])\n",
    "print(similarities[:5])\n",
    "print([math.exp(lgp) for lgp in word_log_probabilities[:5]])\n",
    "print(words[-5:])\n",
    "print(similarities[-5:])\n",
    "print([math.exp(lgp) for lgp in word_log_probabilities[-5:]])\n",
    "print(google_news_wv.similarity(\"hot\", \"cold\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"warm\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"spicy\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"Prescription_Solutions\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"Pharmaceutical_Research\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"GNI\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"dog\"))\n",
    "print(google_news_wv.similarity(\"hot\", \"trunk\"))\n",
    "print(google_news_wv.similarity(\"boat\", \"fuzzy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
