{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97556bc6",
   "metadata": {},
   "source": [
    "# Using Word2Vec Embedding to extend POC Guesser\n",
    "\n",
    "We can use Gensim to make a more powerful version of our Proof-of-Concept. The main limitation will be guesses that lie outside of the training corpora; we might tackle this later with FastText. For now, let's see if we can make less of a toy version using the Google News Skip-Gram model with 300-feature embeddings (requires ~2GB).\n",
    "\n",
    "Make sure to update SSL Certificate to download if required: \n",
    "```\n",
    "pip install -U certifi\n",
    "\n",
    "/Applications/Python 3.X/Install Certificates.command\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea025752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200000 from saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import gensim.models\n",
    "\n",
    "saved_path_name = \"word2vec-google-news-300_c\"\n",
    "limit = 200_000\n",
    "\n",
    "if not os.path.exists(saved_path_name):\n",
    "    print(\"Checking cache and downloading\")\n",
    "    google_news_wv = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "    google_news_wv.save_word2vec_format(saved_path_name)\n",
    "    print(\"Saved to disk in C format\")\n",
    "    del google_news_wv\n",
    "\n",
    "print(f\"Loading {limit} from saved\")\n",
    "google_news_wv = gensim.models.KeyedVectors.load_word2vec_format(saved_path_name, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf202df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "word #0/200000 is </s>\n",
      "word #1/200000 is in\n",
      "word #2/200000 is for\n",
      "word #3/200000 is that\n",
      "word #4/200000 is is\n",
      "word #5/200000 is on\n",
      "word #6/200000 is ##\n",
      "word #7/200000 is The\n",
      "word #8/200000 is with\n",
      "word #9/200000 is said\n"
     ]
    }
   ],
   "source": [
    "print(len(google_news_wv.index_to_key))\n",
    "for index, word in enumerate(google_news_wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(google_news_wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0228c98",
   "metadata": {},
   "source": [
    "Let's see if the model has each of our official words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24e5c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIENCE-FICTION\n",
      "FRANCE\n",
      "CYCLOPS\n",
      "EGYPT\n",
      "EXTRA-TERRESTRIAL\n",
      "CALENDA\n",
      "GERMANY\n",
      "QUEBEC\n",
      "PEGASUS\n",
      "ARMOUR\n",
      "CENTAUR\n",
      "AFRICA\n",
      "RUSSIA\n",
      "SLAUGHTER-HOUSE\n",
      "THEATRE\n",
      "MOUSTACHE\n"
     ]
    }
   ],
   "source": [
    "import decryptogame as dg\n",
    "\n",
    "for word in dg.official_words.english.words:\n",
    "    if word.lower() not in google_news_wv:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b940a",
   "metadata": {},
   "source": [
    "I suspect this may just be a matter of capitalization, formatting, and British spellings. Let's see if we can make a mapping; if not we can use the weak linearity of Word2Vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473aa2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def official_keyword_to_word(keyword: str):\n",
    "    typos = { \"CALENDA\": \"calendar\"}\n",
    "    if keyword in typos:\n",
    "        return typos[keyword]\n",
    "    proper_nouns = [\n",
    "        \"AFRICA\",\n",
    "        \"CENTAUR\",\n",
    "        \"CYCLOPS\",\n",
    "        \"EGYPT\",\n",
    "        \"FRANCE\",\n",
    "        \"GERMANY\",\n",
    "        \"PEGASUS\",\n",
    "        \"QUEBEC\",\n",
    "        \"RUSSIA\"\n",
    "    ]\n",
    "    if keyword in proper_nouns:\n",
    "        return keyword.capitalize()\n",
    "    british = {\n",
    "        \"ARMOUR\": \"armor\",\n",
    "        \"MOUSTACHE\": \"mustache\",\n",
    "        \"THEATRE\": \"theater\",\n",
    "    }\n",
    "    if keyword in british:\n",
    "        return british[keyword]\n",
    "    if '-' in keyword:\n",
    "        if keyword == \"SCIENCE-FICTION\":\n",
    "            keyword = keyword.replace('-', '_')\n",
    "        keyword = keyword.replace('-', '')\n",
    "    return keyword.lower()\n",
    "\n",
    "if any(official_keyword_to_word(keyword) not in google_news_wv for keyword in dg.official_words.english.words):\n",
    "    print(\"Gonna have to improvise\")\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34726307",
   "metadata": {},
   "source": [
    "Looks like we don't need to improvise! Let's see what the keywords the creators chose look like using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccea1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
