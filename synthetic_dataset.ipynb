{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating better clue datasets\n",
    "\n",
    "I don't have a labelled dataset because none of my friends want to come up with thousands of clues with me :(\n",
    "    \n",
    "To create some clues that are based on having similar meaning or based on words triggered by a codeword, we can use the [Datamuse API](https://www.datamuse.com/api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200000 keys\n"
     ]
    }
   ],
   "source": [
    "# load pretrained word2vec model\n",
    "import word2vec_loader as wv_loader\n",
    "\n",
    "limit = 200_000\n",
    "print(f\"Loading {limit} keys\")\n",
    "google_news_wv = wv_loader.load_word2vec_keyedvectors(wv_loader.GOOGLE_NEWS_PATH_NAME, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meaning dataset\n",
      "Loading triggerword dataset\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import decryptogame as dg\n",
    "import json\n",
    "import os\n",
    "\n",
    "def datamuse_url(endpoint: str, words: list[str]): # can add stuff for prefix/suffix support later\n",
    "    query_str = '+'.join(words)\n",
    "    return f\"https://api.datamuse.com/{endpoint}={query_str}\"\n",
    "\n",
    "async def fetch_text_response(session, url, return_id=None):\n",
    "    # return ID let's us associate the result with a paramater\n",
    "    # this allows us to know which word the reponse text is associated with\n",
    "    # despite being called asynchronously\n",
    "    async with session.get(url) as response:\n",
    "        text = await response.text()\n",
    "        return return_id, text\n",
    "\n",
    "async def fetch_text_responses(urls, return_ids):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        api_calls = [fetch_text_response(session, *args) for args in zip(urls, return_ids)]\n",
    "        return [await response for response in asyncio.as_completed(api_calls)]\n",
    "\n",
    "def create_dataset_dict(responses):\n",
    "    meaning_dataset = {}\n",
    "    for word, response in responses:\n",
    "        response_object = json.loads(response)\n",
    "        meaning_dataset[word] = response_object\n",
    "    return meaning_dataset\n",
    "\n",
    "\n",
    "# process responses for local storage\n",
    "\n",
    "async def load_dataset_from_path(path_str, endpoint: str, words):\n",
    "    if not os.path.exists(path_str):\n",
    "\n",
    "        urls = [datamuse_url(endpoint, [word]) for word in words]\n",
    "        responses = await fetch_text_responses(urls, words)\n",
    "\n",
    "        dataset = create_dataset_dict(responses)\n",
    "\n",
    "        with open(path_str, 'w') as f:\n",
    "            json.dump(dataset, f)\n",
    "    else:\n",
    "        with open(path_str) as f:\n",
    "            dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "meaning_dataset_path = \"meaning.json\"\n",
    "triggerword_dataset_path = \"trigger_word.json\"\n",
    "\n",
    "official_words = list(map(wv_loader.official_keyword_to_word, dg.official_words.english.words))\n",
    "\n",
    "print(\"Loading meaning dataset\")\n",
    "meaning_dataset = await load_dataset_from_path(meaning_dataset_path, \"words?ml\", official_words)\n",
    "\n",
    "print(\"Loading triggerword dataset\")\n",
    "triggerword_dataset = await load_dataset_from_path(triggerword_dataset_path, \"words?rel_trg\", official_words)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can use the similar meaning and trigger word datasets to come up with reasonable clues that would be more of a challenge for our Guesser. That is, let's see if we can make clues that follow the rules and that I might be able to guess myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WINTER', 'PATH', 'FESTIVAL', 'POISON')\n",
      "(0, 1, 3)\n",
      "('summer', 'driveway', 'plague')\n",
      "('skiing', 'node', 'pill')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def filter_illegal_cluewords(legal_clue_func, datamuse_dataset):\n",
    "    filtered_dataset = {}\n",
    "    for keyword, info in datamuse_dataset.items():\n",
    "        legal_info = [word_info for word_info in info if legal_clue_func(keyword, word_info[\"word\"])]\n",
    "        filtered_dataset[keyword] = legal_info\n",
    "    return filtered_dataset        \n",
    "\n",
    "def clueword_from_dataset(datamuse_dataset, code_word, seed=400):\n",
    "    candidate_words = []\n",
    "    scores = []\n",
    "    if not datamuse_dataset[code_word]:\n",
    "        return \"garbage\"\n",
    "    for word_info in datamuse_dataset[code_word]:\n",
    "        candidate_words.append(word_info[\"word\"])\n",
    "        scores.append(word_info[\"score\"])\n",
    "    np_scores = np.asarray(scores)\n",
    "    probabilities = np_scores / np.sum(np_scores)\n",
    "    [clue] = random.Random(seed).choices(candidate_words, probabilities)\n",
    "    return clue\n",
    "\n",
    "def clue_from_codewords(datamuse_dataset, codewords, seed=100):\n",
    "    return tuple(clueword_from_dataset(datamuse_dataset, word, seed=seed) for word in codewords)\n",
    "\n",
    "def legal(keyword, word):\n",
    "    return word not in keyword and word in google_news_wv\n",
    "\n",
    "def codewords(keyword_card, code):\n",
    "    return  [wv_loader.official_keyword_to_word(keyword_card[i]) for i in code]\n",
    "\n",
    "\n",
    "meaning_dataset = filter_illegal_cluewords(legal, meaning_dataset)\n",
    "triggerword_dataset = filter_illegal_cluewords(legal, triggerword_dataset)\n",
    "\n",
    "keyword_card_length = 4\n",
    "\n",
    "[test_keyword_card] = next(dg.generators.RandomKeywordCards(card_lengths=[keyword_card_length], seed=200))\n",
    "[test_code] = next(dg.generators.RandomCodes([test_keyword_card], seed=200))\n",
    "test_codewords = codewords(test_keyword_card, test_code)\n",
    "\n",
    "print(test_keyword_card)\n",
    "print(test_code)\n",
    "\n",
    "meaning_clue = clue_from_codewords(meaning_dataset, test_codewords)\n",
    "triggerword_clue = clue_from_codewords(triggerword_dataset, test_codewords)\n",
    "\n",
    "print(meaning_clue)\n",
    "print(triggerword_clue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are some reasonable clues! Let's save a csv for ease-of-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword1</th>\n",
       "      <th>keyword2</th>\n",
       "      <th>keyword3</th>\n",
       "      <th>keyword4</th>\n",
       "      <th>clue1</th>\n",
       "      <th>clue2</th>\n",
       "      <th>clue3</th>\n",
       "      <th>code_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>electricians</td>\n",
       "      <td>leg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>electricians</td>\n",
       "      <td>bloodline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>leg</td>\n",
       "      <td>electricians</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>leg</td>\n",
       "      <td>bloodline</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUTTERFLY</td>\n",
       "      <td>PLUMBER</td>\n",
       "      <td>FOOT</td>\n",
       "      <td>BLOOD</td>\n",
       "      <td>throttle</td>\n",
       "      <td>bloodline</td>\n",
       "      <td>electricians</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keyword1 keyword2 keyword3 keyword4     clue1         clue2         clue3  \\\n",
       "0  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle  electricians           leg   \n",
       "1  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle  electricians     bloodline   \n",
       "2  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle           leg  electricians   \n",
       "3  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle           leg     bloodline   \n",
       "4  BUTTERFLY  PLUMBER     FOOT    BLOOD  throttle     bloodline  electricians   \n",
       "\n",
       "   code_index  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from itertools import permutations\n",
    "\n",
    "def all_possible_codes(keyword_card_length=4, clue_length=3):\n",
    "    return list(permutations(range(keyword_card_length), clue_length))\n",
    "\n",
    "\n",
    "meaning_csv = \"meaning_clues.csv\"\n",
    "triggerword_csv = \"triggerword_clues.csv\"\n",
    "\n",
    "if not os.path.exists(meaning_csv) or not os.path.exists(triggerword_csv):\n",
    "\n",
    "    num_keyword_cards = 1500\n",
    "    codes = all_possible_codes()\n",
    "    keyword_card_generator = dg.generators.RandomKeywordCards(card_lengths=[keyword_card_length], seed=100)\n",
    "\n",
    "    meaning_data = []\n",
    "    triggerword_data = []\n",
    "    for _, [keyword_card] in zip(range(num_keyword_cards), keyword_card_generator):\n",
    "        for i, code in enumerate(codes):\n",
    "            meaning_clue = clue_from_codewords(meaning_dataset, codewords(keyword_card, code))\n",
    "            meaning_data.append(keyword_card + meaning_clue + (i,))\n",
    "            \n",
    "            triggerword_clue = clue_from_codewords(triggerword_dataset, codewords(keyword_card, code))\n",
    "            triggerword_data.append(keyword_card + triggerword_clue + (i,))\n",
    "\n",
    "    header = [\"keyword1\", \"keyword2\", \"keyword3\", \"keyword4\", \"clue1\",  \"clue2\",  \"clue3\", \"code_index\"]\n",
    "    meaning_df = pandas.DataFrame(meaning_data, columns=header)\n",
    "    triggerword_df = pandas.DataFrame(triggerword_data, columns=header)\n",
    "                                      \n",
    "    meaning_df.to_csv(meaning_csv, index=False)\n",
    "    triggerword_df.to_csv(triggerword_csv, index=False)\n",
    "\n",
    "else:\n",
    "    meaning_df = pandas.read_csv(meaning_csv)\n",
    "\n",
    "meaning_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have tens of thousands of clues to reference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
